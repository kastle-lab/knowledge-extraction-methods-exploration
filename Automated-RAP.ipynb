{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15148baf-ae59-4713-ba91-47498d149637",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from time import sleep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e90e2a8-c866-4ae3-8d9a-4ab9ba57bc61",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ollama_interface import chat_with_model # local ollama wrapper\n",
    "from openai import OpenAI\n",
    "from anthropic import Anthropic\n",
    "\n",
    "def interact_with_agent(model_name, system_message, user_prompt, image_paths=None, stream=False, options = None):\n",
    "    \"\"\"Interacts with a model agent using system and user prompts.\"\"\"\n",
    "    \n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": system_message},\n",
    "        {\"role\": \"user\", \"content\": user_prompt}\n",
    "    ]\n",
    "\n",
    "    if model_name == \"gpt-4o\":\n",
    "        client = OpenAI(api_key=\"\")\n",
    "\n",
    "        response = client.chat.completions.create(\n",
    "            model=\"gpt-4o\",\n",
    "            messages=messages\n",
    "        )\n",
    "\n",
    "        return response.choices[0].message.content.strip()\n",
    "\n",
    "    elif model_name == \"claude-sonnet-4-20250514\":\n",
    "        client = Anthropic(api_key=\"\")\n",
    "        response = client.messages.create(\n",
    "            model=model_name,\n",
    "            system=system_message,\n",
    "            messages=[\n",
    "                {\"role\": \"user\", \"content\": user_prompt}\n",
    "            ],\n",
    "            max_tokens=8192\n",
    "        )\n",
    "\n",
    "        return response.content[0].text.strip()\n",
    "        \n",
    "    else:\n",
    "        response = chat_with_model(\n",
    "            model_name=model_name,\n",
    "            messages=messages,\n",
    "            # image_paths=image_paths or [],\n",
    "            stream=stream,\n",
    "            options=options,\n",
    "            timeout=30*60*60\n",
    "        )\n",
    "        return response[\"message\"][\"content\"]\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e6a7cbb-9771-4472-9d14-e255dec900b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_file_to_string(file_path):\n",
    "  \"\"\"Loads the content of a file into a string.\n",
    "\n",
    "  Args:\n",
    "    file_path: The path to the file.\n",
    "\n",
    "  Returns:\n",
    "    The content of the file as a string.\n",
    "  \"\"\"\n",
    "  with open(file_path, 'r') as file:\n",
    "    file_contents = file.read()\n",
    "  return file_contents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fd6839e-0071-4f24-b9ce-914d7e2a27dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fill_prompt_template(template_text, values_dict):\n",
    "    for key, value in values_dict.items():\n",
    "        template_text = template_text.replace(f\"{{{key}}}\", value)\n",
    "    return template_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d834f2bf-f1a7-4497-a068-0f42246d0da9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def agent_call(agent):\n",
    "    response = interact_with_agent(\n",
    "        model_name=agent[\"model\"],\n",
    "        system_message=agent[\"system_message\"],\n",
    "        user_prompt=agent[\"prompt\"]\n",
    "    )\n",
    "    return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fc232c9-5314-4b00-85f5-7bb7e528898d",
   "metadata": {},
   "outputs": [],
   "source": [
    "pub_path = \"publication.md\"\n",
    "pub_string = load_file_to_string(pub_path)\n",
    "pub = pub_string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8665820b-d24b-4a04-a925-593befce21f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def master_func(model_name, schema_complete, schema_paring, lit_paring, example_provision):\n",
    "\n",
    "    if schema_complete:\n",
    "\n",
    "        update_schema = False\n",
    "        update_lit = False\n",
    "        \n",
    "        if schema_paring and not lit_paring:\n",
    "\n",
    "            update_schema = True\n",
    "            \n",
    "            agent1_sys = \"\"\"\n",
    "            You are an expert knowledge extraction analyst.\n",
    "            \n",
    "            You are given:\n",
    "             - A set of schema triples in the format (subject, predicate, object), which define a knowledge schema\n",
    "             - A scientific publication or report in markdown format\n",
    "             \n",
    "            Your task is to review the schema and determine which triples are realistically populatable based on the kind of information found in the publication — not to extract the actual data values.\n",
    "            \n",
    "            Only include triples for which:\n",
    "             - The publication clearly discusses or covers the subject matter described in the triple.\n",
    "             - There is a strong indication that data could be extracted to populate the triple, even if not extracted now\n",
    "            \n",
    "            Do not include:\n",
    "             - Triples that refer to topics or entities not mentioned at all in the publication\n",
    "             - Triples for which the necessary information is missing or unlikely to be derivable from the content\n",
    "            \n",
    "            Output only the subset of relevant schema triples — the ones that appear potentially populatable — in CSV format\n",
    "            \"\"\"\n",
    "            \n",
    "            agent1_usr = \"\"\"\n",
    "            Task: Read the publication and filter the schema triples. Output only those triples for which there is evidence that the information is likely present or derivable from the publication.\n",
    "            \n",
    "            Do not extract or fill in the data. Only identify which schema triples are realistically populatable based on content coverage.\n",
    "            \n",
    "            Output format:\n",
    "            A CSV list of supported triples in this format:\n",
    "            \"subject,predicate,object\"\n",
    "            \n",
    "            Schema: \\\"\\\"\\\"\n",
    "            {schema}\n",
    "            \\\"\\\"\\\"\n",
    "            \n",
    "            Publication: \\\"\\\"\\\"\n",
    "            {publication}\n",
    "            \\\"\\\"\\\"\n",
    "            \"\"\"\n",
    "    \n",
    "        elif not schema_paring and lit_paring:\n",
    "\n",
    "            update_lit = True\n",
    "            \n",
    "            agent1_sys = \"\"\"\n",
    "            You are an expert knowledge extraction analyst.\n",
    "            \n",
    "            You are given:\n",
    "             - A set of schema triples in the format (subject, predicate, object), which define a knowledge schema\n",
    "             - A scientific publication or report in markdown format\n",
    "             \n",
    "            Your task is to review the schema and extract pieces of the publication that can realistically populatable the given schema triples.\n",
    "            \n",
    "            Only include the publication data extract for which:\n",
    "             - The publication clearly discusses or covers the subject matter described in the triple.\n",
    "             - There is a strong indication that data could be extracted to populate the triple, even if not extracted now\n",
    "            \n",
    "            Do not:\n",
    "             - Change or rephrase anything in the publication but keep the wording as text as it is.\n",
    "             - include data extracts for which the necessary information is missing or unlikely to be derivable from the content\n",
    "            \n",
    "            Output only the subset publication extract — in markdown format\n",
    "            \"\"\"\n",
    "    \n",
    "            agent1_usr = \"\"\"\n",
    "            Task: Read the publication and the schema triples. Output only those publication extracts for which there is evidence that the information is likely present or derivable and can populate the triples.\n",
    "            \n",
    "            Do not change or rephrase the publication wording but give exact same wording. Only identify the sub-extracts of the publication that can realistically populate triples based on content coverage.\n",
    "            \n",
    "            Output format:\n",
    "            A markdown of the exact extracts of the publication:\n",
    "            \n",
    "            Schema: \\\"\\\"\\\"\n",
    "            {schema}\n",
    "            \\\"\\\"\\\"\n",
    "            \n",
    "            Publication: \\\"\\\"\\\"\n",
    "            {publication}\n",
    "            \\\"\\\"\\\"\n",
    "            \"\"\"\n",
    "\n",
    "        schema_path = \"triples.csv\"\n",
    "        schema_string = load_file_to_string(schema_path)\n",
    "        schema = schema_string\n",
    "\n",
    "        input_data = {\n",
    "            \"publication\": pub,\n",
    "            \"schema\": schema\n",
    "        }\n",
    "        agent1_prompt = fill_prompt_template(agent1_usr, input_data)\n",
    "\n",
    "        agent1 = {\n",
    "            \"name\": \"schema_extraction_agent\",\n",
    "            \"model\": model_name,\n",
    "            \"system_message\": agent1_sys,\n",
    "            \"prompt\": agent1_prompt\n",
    "        }\n",
    "\n",
    "        response = agent_call(agent1)\n",
    "        file_path_write = f\"{model_name}-{str(schema_complete)}-{str(schema_paring)}-{str(lit_paring)}-{str(example_provision)}-schema-lit-extraction.txt\"\n",
    "        with open(file_path_write, 'w') as f:\n",
    "            f.write(response)\n",
    "\n",
    "        ## Agent 1 calls complete\n",
    "\n",
    "        \n",
    "        # Prep for Agent 2\n",
    "        if not example_provision:\n",
    "            \n",
    "            agent2_sys = \"\"\"\n",
    "            You are an expert in precise information extraction.\n",
    "            \n",
    "            You are given:\n",
    "             - A list of schema triples in the form: (subject, predicate, object) — each defines a relation pattern that is expected to be supported by the publication\n",
    "             - A publication in markdown format\n",
    "            \n",
    "            Your task is to:\n",
    "             - Carefully read the publication\n",
    "             - Extract all factual data triples from the publication that match the patterns defined in the schema\n",
    "             - Only extract triples that are explicitly stated or clearly inferable from the publication\n",
    "             - Return only the final data triples extracted\n",
    "            \n",
    "            Guidelines:\n",
    "             - Only include triples that adhere to the schema exactly\n",
    "             - Do not include unsupported, hypothetical, or guessed information\n",
    "             - If multiple valid triples fit the same schema (e.g., multiple values), include them all\n",
    "             - Do not include input schema triples but only include the extracted data triples\n",
    "             - Output must be a CSV-style list of complete data triples: \"subject,predicate,object\"\n",
    "            \"\"\"\n",
    "    \n",
    "            agent2_usr = \"\"\"\n",
    "            Task: From the publication, extract all factual data triples that match the patterns defined in the schema.\n",
    "            \n",
    "            Only extract triples if they are explicitly stated or clearly inferable. Return one CSV-formatted triple per line.\n",
    "            \n",
    "            Format:\n",
    "            \"subject,predicate,object\"\n",
    "            \n",
    "            Schema: \\\"\\\"\\\"\n",
    "            {schema}\n",
    "            \\\"\\\"\\\"\n",
    "            \n",
    "            Publication: \\\"\\\"\\\"\n",
    "            {publication}\n",
    "            \\\"\\\"\\\"\n",
    "            \"\"\"\n",
    "\n",
    "        else:\n",
    "            agent2_sys = \"\"\"\n",
    "            You are an expert in precise information extraction.\n",
    "            \n",
    "            You are given:\n",
    "             - A list of schema triples in the form: (subject, predicate, object) — each defines a relation pattern that is expected to be supported by the publication\n",
    "             - A publication in markdown format\n",
    "            \n",
    "            Your task is to:\n",
    "             - Carefully read the publication\n",
    "             - Analyze the provided examples for populating triples with data\n",
    "             - Extract all factual data triples from the publication that match the patterns defined in the schema using the examples as a guide\n",
    "             - Only extract triples that are explicitly stated or clearly inferable from the publication\n",
    "             - Return only the final data triples extracted\n",
    "            \n",
    "            Guidelines:\n",
    "             - Only include triples that adhere to the schema exactly\n",
    "             - Do not include unsupported, hypothetical, or guessed information\n",
    "             - If multiple valid triples fit the same schema (e.g., multiple values), include them all\n",
    "             - Do not include input schema triples but only include the extracted data triples\n",
    "             - Output must be a CSV-style list of complete data triples: \"subject,predicate,object\"\n",
    "            \"\"\"\n",
    "    \n",
    "            agent2_usr = \"\"\"\n",
    "            Task: From the publication, extract all factual data triples that match the patterns defined in the schema.\n",
    "            \n",
    "            Only extract triples if they are explicitly stated or clearly inferable. Return one CSV-formatted triple per line.\n",
    "\n",
    "            Below are examples of what a triple in the schema could become when populated with data.\n",
    "\n",
    "            Examples:\n",
    "            1. Material,hasProperty,Property -> Polyethylene,hasProperty,Density: 0.95 g/cm³\n",
    "            2. Experiment,hasLocation,Location -> Experiment001,hasLocation,MIT Laboratory 3B\n",
    "            3. DifferentialScanningCalorimetry,hasCalorimetryCharacteristic,CoolingRate -> DSC_Exp12,hasCalorimetryCharacteristic,CoolingRate: 10 °C/min\n",
    "            4. Rheometry,hasRheometryCharacteristic,CapillarySize -> RheoTest22,hasRheometryCharacteristic,CapillarySize: 0.5 mm\n",
    "            5. TransmissionElectronMicroscopy,hasMicrscopyCharacteristic,Magnification -> TEM_SampleA,hasMicrscopyCharacteristic,Magnification: 50000x\n",
    "            6. Collection,hasDOI,xsd:anyURI -> NanocompositeStudy2023,hasDOI,https://doi.org/10.1016/j.polymer.2023.125\n",
    "            7. Reference,hasAuthor,Author -> Ref1234,hasAuthor,Jane Smith\n",
    "            8. Material,hasComponent,Material -> EpoxyResinBlend,hasComponent,CarbonNanotubes\n",
    "            9. Computation,hasSoftwareConfiguration,SoftwareConfiguration -> MDRun45,hasSoftwareConfiguration,LAMMPS v3.2\n",
    "            10. Data,hasSamplePreparation,PhysicalProcess -> DataSet_AlFoam,hasSamplePreparation,HeatTreatment950C\n",
    "            11. CharacterizationMethod,hasResultData,ResultData -> SEM_Char2022,hasResultData,SEM_Results_Char22.csv\n",
    "            12. FiberTensileStrength,isMeasuredUnderCondition,Conditions -> FiberX_2021,isMeasuredUnderCondition,Temperature: 25 °C\n",
    "            13. TensileModulus,isMeasuredUnderCondition,Conditions -> PLA_Sample7,isMeasuredUnderCondition,StrainRate: 0.01 /s\n",
    "            14. Material,hasProperty,SpecificSurfaceArea -> SiO2_Powder_A,hasProperty,SSA_SiO2_A\n",
    "            15. SpecificSurfaceArea,hasQuantity,Value -> SSA_SiO2_A,hasQuantity,200 m²/g\n",
    "            16. Additive,hasQuantity,Quantity -> TiO2_Nanoparticles,hasQuantity,3 wt%\n",
    "\n",
    "            Format:\n",
    "            \"subject,predicate,object\"\n",
    "            \n",
    "            Schema: \\\"\\\"\\\"\n",
    "            {schema}\n",
    "            \\\"\\\"\\\"\n",
    "            \n",
    "            Publication: \\\"\\\"\\\"\n",
    "            {publication}\n",
    "            \\\"\\\"\\\"\n",
    "            \"\"\"\n",
    "\n",
    "        if update_schema and not update_lit:\n",
    "            input_data2 = {\n",
    "                \"publication\": pub,\n",
    "                \"schema\": response\n",
    "            }\n",
    "\n",
    "        elif not update_schema and update_lit:\n",
    "            input_data2 = {\n",
    "                \"publication\": response,\n",
    "                \"schema\": schema\n",
    "            }\n",
    "            \n",
    "        agent2_prompt = fill_prompt_template(agent2_usr, input_data2)\n",
    "\n",
    "        agent2 = {\n",
    "            \"name\": \"knowledge_extraction_agent\",\n",
    "            \"model\": model_name,\n",
    "            \"system_message\": agent2_sys,\n",
    "            \"prompt\": agent2_prompt\n",
    "        }\n",
    "\n",
    "        response_2 = agent_call(agent2)\n",
    "        file_path_write = f\"{model_name}-{str(schema_complete)}-{str(schema_paring)}-{str(lit_paring)}-{str(example_provision)}-knowledge-extraction.csv\"\n",
    "        with open(file_path_write, 'w') as f:\n",
    "            f.write(response_2)\n",
    "            \n",
    "    elif not schema_complete:\n",
    "\n",
    "        update_schema = False\n",
    "        update_lit = False\n",
    "        \n",
    "        if schema_paring and not lit_paring:\n",
    "\n",
    "            update_schema = True\n",
    "            \n",
    "            agent1_sys = \"\"\"\n",
    "            You are an expert knowledge extraction analyst.\n",
    "            \n",
    "            You are given:\n",
    "             - A set of schema triples in the format (subject, predicate, object), which define a knowledge schema\n",
    "             - A scientific publication or report in markdown format\n",
    "             \n",
    "            Your task is to review the schema and determine which triples are realistically populatable based on the kind of information found in the publication — not to extract the actual data values.\n",
    "            \n",
    "            Only include triples for which:\n",
    "             - The publication clearly discusses or covers the subject matter described in the triple.\n",
    "             - There is a strong indication that data could be extracted to populate the triple, even if not extracted now\n",
    "            \n",
    "            Do not include:\n",
    "             - Triples that refer to topics or entities not mentioned at all in the publication\n",
    "             - Triples for which the necessary information is missing or unlikely to be derivable from the content\n",
    "            \n",
    "            Output only the subset of relevant schema triples — the ones that appear potentially populatable — in CSV format\n",
    "            \"\"\"\n",
    "            \n",
    "            agent1_usr = \"\"\"\n",
    "            Task: Read the publication and filter the schema triples. Output only those triples for which there is evidence that the information is likely present or derivable from the publication.\n",
    "            \n",
    "            Do not extract or fill in the data. Only identify which schema triples are realistically populatable based on content coverage.\n",
    "            \n",
    "            Output format:\n",
    "            A CSV list of supported triples in this format:\n",
    "            \"subject,predicate,object\"\n",
    "            \n",
    "            Schema: \\\"\\\"\\\"\n",
    "            {schema}\n",
    "            \\\"\\\"\\\"\n",
    "            \n",
    "            Publication: \\\"\\\"\\\"\n",
    "            {publication}\n",
    "            \\\"\\\"\\\"\n",
    "            \"\"\"\n",
    "    \n",
    "        elif not schema_paring and lit_paring:\n",
    "\n",
    "            update_lit = True\n",
    "            \n",
    "            agent1_sys = \"\"\"\n",
    "            You are an expert knowledge extraction analyst.\n",
    "            \n",
    "            You are given:\n",
    "             - A set of schema triples in the format (subject, predicate, object), which define a knowledge schema\n",
    "             - A scientific publication or report in markdown format\n",
    "             \n",
    "            Your task is to review the schema and extract pieces of the publication that can realistically populatable the given schema triples.\n",
    "            \n",
    "            Only include the publication data extract for which:\n",
    "             - The publication clearly discusses or covers the subject matter described in the triple.\n",
    "             - There is a strong indication that data could be extracted to populate the triple, even if not extracted now\n",
    "            \n",
    "            Do not:\n",
    "             - Change or rephrase anything in the publication but keep the wording as text as it is.\n",
    "             - include data extracts for which the necessary information is missing or unlikely to be derivable from the content\n",
    "            \n",
    "            Output only the subset publication extract — in markdown format\n",
    "            \"\"\"\n",
    "    \n",
    "            agent1_usr = \"\"\"\n",
    "            Task: Read the publication and the schema triples. Output only those publication extracts for which there is evidence that the information is likely present or derivable and can populate the triples.\n",
    "            \n",
    "            Do not change or rephrase the publication wording but give exact same wording. Only identify the sub-extracts of the publication that can realistically populate triples based on content coverage.\n",
    "            \n",
    "            Output format:\n",
    "            A markdown of the exact extracts of the publication:\n",
    "            \n",
    "            Schema: \\\"\\\"\\\"\n",
    "            {schema}\n",
    "            \\\"\\\"\\\"\n",
    "            \n",
    "            Publication: \\\"\\\"\\\"\n",
    "            {publication}\n",
    "            \\\"\\\"\\\"\n",
    "            \"\"\"\n",
    "\n",
    "        for filename in sorted(os.listdir(\"csv\")):\n",
    "            if filename.endswith(\".csv\"):\n",
    "                schema_path = os.path.join(\"csv\", filename)\n",
    "                schema = load_file_to_string(schema_path)\n",
    "                \n",
    "                input_data = {\n",
    "                    \"publication\": pub,\n",
    "                    \"schema\": schema\n",
    "                }\n",
    "                agent1_prompt = fill_prompt_template(agent1_usr, input_data)\n",
    "                \n",
    "                agent1 = {\n",
    "                    \"name\": \"schema_extraction_agent\",\n",
    "                    \"model\": model_name,\n",
    "                    \"system_message\": agent1_sys,\n",
    "                    \"prompt\": agent1_prompt\n",
    "                }\n",
    "        \n",
    "                response = agent_call(agent1)\n",
    "\n",
    "                base, _ = os.path.splitext(filename)\n",
    "                new_filename = base + \".txt\"\n",
    "                dir_name = f\"{model_name}-{str(schema_complete)}-{str(schema_paring)}-{str(lit_paring)}-{str(example_provision)}-schema-lit-extraction\"\n",
    "                os.makedirs(dir_name, exist_ok=True)\n",
    "                file_path_write = os.path.join(dir_name, new_filename)\n",
    "                with open(file_path_write, 'w') as f:\n",
    "                    f.write(response)\n",
    "\n",
    "        if not example_provision:\n",
    "            \n",
    "            agent2_sys = \"\"\"\n",
    "            You are an expert in precise information extraction.\n",
    "            \n",
    "            You are given:\n",
    "             - A list of schema triples in the form: (subject, predicate, object) — each defines a relation pattern that is expected to be supported by the publication\n",
    "             - A publication in markdown format\n",
    "            \n",
    "            Your task is to:\n",
    "             - Carefully read the publication\n",
    "             - Extract all factual data triples from the publication that match the patterns defined in the schema\n",
    "             - Only extract triples that are explicitly stated or clearly inferable from the publication\n",
    "             - Return only the final data triples extracted\n",
    "            \n",
    "            Guidelines:\n",
    "             - Only include triples that adhere to the schema exactly\n",
    "             - Do not include unsupported, hypothetical, or guessed information\n",
    "             - If multiple valid triples fit the same schema (e.g., multiple values), include them all\n",
    "             - Do not include input schema triples but only include the extracted data triples\n",
    "             - Output must be a CSV-style list of complete data triples: \"subject,predicate,object\"\n",
    "            \"\"\"\n",
    "    \n",
    "            agent2_usr = \"\"\"\n",
    "            Task: From the publication, extract all factual data triples that match the patterns defined in the schema.\n",
    "            \n",
    "            Only extract triples if they are explicitly stated or clearly inferable. Return one CSV-formatted triple per line.\n",
    "            \n",
    "            Format:\n",
    "            \"subject,predicate,object\"\n",
    "            \n",
    "            Schema: \\\"\\\"\\\"\n",
    "            {schema}\n",
    "            \\\"\\\"\\\"\n",
    "            \n",
    "            Publication: \\\"\\\"\\\"\n",
    "            {publication}\n",
    "            \\\"\\\"\\\"\n",
    "            \"\"\"\n",
    "\n",
    "        else:\n",
    "            agent2_sys = \"\"\"\n",
    "            You are an expert in precise information extraction.\n",
    "            \n",
    "            You are given:\n",
    "             - A list of schema triples in the form: (subject, predicate, object) — each defines a relation pattern that is expected to be supported by the publication\n",
    "             - A publication in markdown format\n",
    "            \n",
    "            Your task is to:\n",
    "             - Carefully read the publication\n",
    "             - Analyze the provided examples for populating triples with data\n",
    "             - Extract all factual data triples from the publication that match the patterns defined in the schema using the examples as a guide\n",
    "             - Only extract triples that are explicitly stated or clearly inferable from the publication\n",
    "             - Return only the final data triples extracted\n",
    "            \n",
    "            Guidelines:\n",
    "             - Only include triples that adhere to the schema exactly\n",
    "             - Do not include unsupported, hypothetical, or guessed information\n",
    "             - If multiple valid triples fit the same schema (e.g., multiple values), include them all\n",
    "             - Do not include input schema triples but only include the extracted data triples\n",
    "             - Output must be a CSV-style list of complete data triples: \"subject,predicate,object\"\n",
    "            \"\"\"\n",
    "    \n",
    "            agent2_usr = \"\"\"\n",
    "            Task: From the publication, extract all factual data triples that match the patterns defined in the schema.\n",
    "            \n",
    "            Only extract triples if they are explicitly stated or clearly inferable. Return one CSV-formatted triple per line.\n",
    "\n",
    "            Below are examples of what a triple in the schema could become when populated with data.\n",
    "\n",
    "            Examples:\n",
    "            1. Material,hasProperty,Property -> Polyethylene,hasProperty,Density: 0.95 g/cm³\n",
    "            2. Experiment,hasLocation,Location -> Experiment001,hasLocation,MIT Laboratory 3B\n",
    "            3. DifferentialScanningCalorimetry,hasCalorimetryCharacteristic,CoolingRate -> DSC_Exp12,hasCalorimetryCharacteristic,CoolingRate: 10 °C/min\n",
    "            4. Rheometry,hasRheometryCharacteristic,CapillarySize -> RheoTest22,hasRheometryCharacteristic,CapillarySize: 0.5 mm\n",
    "            5. TransmissionElectronMicroscopy,hasMicrscopyCharacteristic,Magnification -> TEM_SampleA,hasMicrscopyCharacteristic,Magnification: 50000x\n",
    "            6. Collection,hasDOI,xsd:anyURI -> NanocompositeStudy2023,hasDOI,https://doi.org/10.1016/j.polymer.2023.125\n",
    "            7. Reference,hasAuthor,Author -> Ref1234,hasAuthor,Jane Smith\n",
    "            8. Material,hasComponent,Material -> EpoxyResinBlend,hasComponent,CarbonNanotubes\n",
    "            9. Computation,hasSoftwareConfiguration,SoftwareConfiguration -> MDRun45,hasSoftwareConfiguration,LAMMPS v3.2\n",
    "            10. Data,hasSamplePreparation,PhysicalProcess -> DataSet_AlFoam,hasSamplePreparation,HeatTreatment950C\n",
    "            11. CharacterizationMethod,hasResultData,ResultData -> SEM_Char2022,hasResultData,SEM_Results_Char22.csv\n",
    "            12. FiberTensileStrength,isMeasuredUnderCondition,Conditions -> FiberX_2021,isMeasuredUnderCondition,Temperature: 25 °C\n",
    "            13. TensileModulus,isMeasuredUnderCondition,Conditions -> PLA_Sample7,isMeasuredUnderCondition,StrainRate: 0.01 /s\n",
    "            14. Material,hasProperty,SpecificSurfaceArea -> SiO2_Powder_A,hasProperty,SSA_SiO2_A\n",
    "            15. SpecificSurfaceArea,hasQuantity,Value -> SSA_SiO2_A,hasQuantity,200 m²/g\n",
    "            16. Additive,hasQuantity,Quantity -> TiO2_Nanoparticles,hasQuantity,3 wt%\n",
    "\n",
    "            Format:\n",
    "            \"subject,predicate,object\"\n",
    "            \n",
    "            Schema: \\\"\\\"\\\"\n",
    "            {schema}\n",
    "            \\\"\\\"\\\"\n",
    "            \n",
    "            Publication: \\\"\\\"\\\"\n",
    "            {publication}\n",
    "            \\\"\\\"\\\"\n",
    "            \"\"\"\n",
    "\n",
    "        # if update_schema, we need to iterate through f\"{model_name}-{str(schema_complete)}-{str(schema_paring)}-{str(lit_paring)}-{str(example_provision)}-schema-lit-extraction\"\n",
    "        # and put it as the new schema. the lit will stay the same\n",
    "        # if update_lit, we need to iterate through f\"{model_name}-{str(schema_complete)}-{str(schema_paring)}-{str(lit_paring)}-{str(example_provision)}-schema-lit-extraction\"\n",
    "        # and put it as the new lit. the schema will stay what is in \"csv\"\n",
    "        if update_schema:\n",
    "            schema_dir = f\"{model_name}-{str(schema_complete)}-{str(schema_paring)}-{str(lit_paring)}-{str(example_provision)}-schema-lit-extraction\"\n",
    "        elif update_lit:\n",
    "            pass\n",
    "        for filename in os.listdir(\"csv\"):\n",
    "            if filename.endswith(\".csv\"):\n",
    "                schema_path = os.path.join(\"pared-csv2-promptex-claudesonnet4\", filename)\n",
    "                schema = load_file_to_string(schema_path)\n",
    "        \n",
    "                input_data = {\n",
    "                    \"publication\": pub,\n",
    "                    \"schema\": schema\n",
    "                }\n",
    "                agent2_prompt = fill_prompt_template(agent2_usr, input_data)\n",
    "        \n",
    "                agent2 = {\n",
    "                    \"name\": \"knowledge_extraction_agent\",\n",
    "                    \"model\": \"claude-sonnet-4-20250514\",\n",
    "                    \"system_message\": agent2_sys,\n",
    "                    \"prompt\": agent2_prompt\n",
    "                    #\"image_paths\": [f\"images/{image}\" for image in os.listdir(\"images\") if image.endswith(\".png\")]\n",
    "                }\n",
    "        \n",
    "                response_2 = agent_call(agent2)\n",
    "        \n",
    "                # print(response_2[\"message\"][\"content\"]) # local models\n",
    "                # print(response_2.choices[0].message.content) # gpt\n",
    "                print(response_2.content[0].text) # claude\n",
    "        \n",
    "                file_path_write = os.path.join(\"pared-extracted-csv2-promptex-claudesonnet4\", f\"claude-sonnet4-knowledge-extraction-{filename.split('-')[-1]}\")\n",
    "                with open(file_path_write, 'w') as f:\n",
    "                    # f.write(response_2[\"message\"][\"content\"]) # local models\n",
    "                    # f.write(response_2.choices[0].message.content) # gpt\n",
    "                    f.write(response_2.content[0].text) # claude"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c688d95-e67b-4867-a801-a1f3589da87a",
   "metadata": {},
   "outputs": [],
   "source": [
    "models = [\"phi4:latest-64k\",\n",
    "          \"llama3.2:latest-64k\",\n",
    "          \"phi4-mini:latest-64k\",\n",
    "          \"granite3.3:latest-64k\",\n",
    "          \"gemma3:27b-64k\",\n",
    "          \"mistral-small3.2:latest-64k\",\n",
    "          \"deepseek-r1:latest-64k\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53da3524-0e93-4f56-ae45-e5f70a2a9d73",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combinations (Images = No)\n",
    "\n",
    "# 1. Schema = Complete; Schema Paring = Yes; Literature Paring = No; Examples = No\n",
    "# 2. Schema = Complete; Schema Paring = No; Literature Paring = Yes; Examples = No\n",
    "# 3. Schema = Complete; Schema Paring = Yes; Literature Paring = No; Examples = Yes\n",
    "# 4. Schema = Complete = Schema Paring = No; Literature Paring = Yes; Examples = Yes\n",
    "\n",
    "# 5. Schema = Modules; Schema Paring = Yes; Literature Paring = No; Examples = No\n",
    "# 6. Schema = Modules; Schema Paring = No; Literature Paring = Yes; Examples = No\n",
    "# 7. Schema = Modules; Schema Paring = Yes; Literature Paring = No; Examples = Yes\n",
    "# 8. Schema = Modules; Schema Paring = No; Literature Paring = Yes; Examples = Yes\n",
    "\n",
    "for model in models:\n",
    "    master_func(model_name=model, schema_complete=True, schema_paring=True, lit_paring=False, Examples=False)\n",
    "    master_func(model_name=model, schema_complete=True, schema_paring=False, lit_paring=True, Examples=False)\n",
    "    master_func(model_name=model, schema_complete=True, schema_paring=True, lit_paring=False, Examples=True)\n",
    "    master_func(model_name=model, schema_complete=True, schema_paring=False, lit_paring=True, Examples=True)\n",
    "\n",
    "    master_func(model_name=model, schema_complete=False, schema_paring=True, lit_paring=False, Examples=False)\n",
    "    master_func(model_name=model, schema_complete=False, schema_paring=False, lit_paring=True, Examples=False)\n",
    "    master_func(model_name=model, schema_complete=False, schema_paring=True, lit_paring=False, Examples=True)\n",
    "    master_func(model_name=model, schema_complete=False, schema_paring=False, lit_paring=True, Examples=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
